{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and derived metrics\n",
    "\n",
    "With synthetic raw signals in place we can illustrate how Monumental Labs might normalize them with DuckDB, compute production KPIs, and build a lightweight predictive model for finishing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "con = duckdb.connect(database=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE jobs AS\n",
    "    SELECT * FROM read_csv_auto('{(DATA_DIR / 'jobs.csv').as_posix()}', header=True);\n",
    "    \"\"\"\n",
    ")\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE toolpaths AS\n",
    "    SELECT * FROM read_csv_auto('{(DATA_DIR / 'toolpaths.csv').as_posix()}', header=True);\n",
    "    \"\"\"\n",
    ")\n",
    "con.execute(\n",
    "    f\"\"\"\n",
    "    CREATE OR REPLACE TABLE telemetry AS\n",
    "    SELECT * FROM read_csv_auto('{(DATA_DIR / 'telemetry.csv').as_posix()}', header=True);\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE job_contact AS\n",
    "    SELECT job_id, SUM(contact_time_s) AS total_contact_s\n",
    "    FROM toolpaths\n",
    "    GROUP BY 1;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolpath efficiency\n",
    "\n",
    "We estimate the volume removed per toolpath by allocating each job's total volume based on that toolpath's share of contact time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TABLE toolpath_metrics AS\n",
    "    WITH contact_share AS (\n",
    "        SELECT t.*, j.volume_removed_cm3, jc.total_contact_s,\n",
    "               CASE WHEN jc.total_contact_s = 0 THEN 0\n",
    "                    ELSE t.contact_time_s / jc.total_contact_s END AS share\n",
    "        FROM toolpaths t\n",
    "        JOIN job_contact jc USING (job_id)\n",
    "        JOIN jobs j USING (job_id)\n",
    "    )\n",
    "    SELECT\n",
    "        toolpath_id,\n",
    "        job_id,\n",
    "        feed_mm_min,\n",
    "        rpm,\n",
    "        spindle_current_a,\n",
    "        contact_time_s,\n",
    "        tool_id,\n",
    "        share,\n",
    "        share * volume_removed_cm3 AS estimated_volume_cm3,\n",
    "        CASE WHEN contact_time_s = 0 THEN NULL\n",
    "             ELSE (share * volume_removed_cm3) / contact_time_s END AS toolpath_efficiency_cm3_s\n",
    "    FROM contact_share;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "toolpath_metrics = con.execute(\n",
    "    \"SELECT * FROM toolpath_metrics ORDER BY job_id, toolpath_id LIMIT 5\"\n",
    ").df()\n",
    "toolpath_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool health view\n",
    "\n",
    "A crude wear index is the sum of spindle current multiplied by cutting time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_health = con.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        tool_id,\n",
    "        SUM(spindle_current_a * contact_time_s) AS tool_wear_index,\n",
    "        SUM(contact_time_s) AS total_contact_s,\n",
    "        AVG(spindle_current_a) AS avg_current_a\n",
    "    FROM toolpaths\n",
    "    GROUP BY 1\n",
    "    ORDER BY tool_wear_index DESC;\n",
    "    \"\"\"\n",
    ").df()\n",
    "tool_health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job-level metrics\n",
    "\n",
    "We consolidate job performance to feed the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_metrics = con.execute(\n",
    "    \"\"\"\n",
    "    WITH efficiency AS (\n",
    "        SELECT job_id, AVG(toolpath_efficiency_cm3_s) AS avg_toolpath_efficiency_cm3_s\n",
    "        FROM toolpath_metrics\n",
    "        GROUP BY 1\n",
    "    )\n",
    "    SELECT\n",
    "        j.job_id,\n",
    "        j.material,\n",
    "        j.geometry_complexity,\n",
    "        j.volume_removed_cm3,\n",
    "        j.finish_minutes,\n",
    "        j.quoted_price_usd,\n",
    "        j.scheduled_start,\n",
    "        jc.total_contact_s,\n",
    "        j.volume_removed_cm3 / NULLIF(jc.total_contact_s / 60.0, 0) AS removal_rate_cm3_min,\n",
    "        e.avg_toolpath_efficiency_cm3_s\n",
    "    FROM jobs j\n",
    "    JOIN job_contact jc USING (job_id)\n",
    "    JOIN efficiency e USING (job_id)\n",
    "    ORDER BY j.job_id;\n",
    "    \"\"\"\n",
    ").df()\n",
    "job_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive finishing time\n",
    "\n",
    "We fit a simple linear regression on material, complexity, and average toolpath efficiency to estimate finishing time. The synthetic data keeps the math deterministic yet realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "materials = pd.get_dummies(job_metrics[\"material\"], prefix=\"mat\")\n",
    "features = pd.concat(\n",
    "    [\n",
    "        materials,\n",
    "        job_metrics[[\"geometry_complexity\", \"avg_toolpath_efficiency_cm3_s\", \"removal_rate_cm3_min\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X = features.to_numpy()\n",
    "y = job_metrics[\"finish_minutes\"].to_numpy()\n",
    "X_with_bias = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "coeffs, *_ = np.linalg.lstsq(X_with_bias, y, rcond=None)\n",
    "pred = X_with_bias @ coeffs\n",
    "\n",
    "job_predictions = job_metrics.copy()\n",
    "job_predictions[\"pred_finish_minutes\"] = np.round(pred, 1)\n",
    "job_predictions[\"residual_minutes\"] = job_predictions[\"finish_minutes\"] - job_predictions[\"pred_finish_minutes\"]\n",
    "rmse = np.sqrt(np.mean(np.square(job_predictions[\"residual_minutes\"])) )\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_predictions[[\"job_id\", \"material\", \"finish_minutes\", \"pred_finish_minutes\", \"residual_minutes\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting tables — `jobs`, `toolpaths`, `telemetry`, `toolpath_metrics`, `tool_health`, and `job_predictions` — feed directly into the Streamlit dashboard to highlight throughput, economics, and maintenance signals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
